{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaEatzN-xpYA"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bof8R1rExouT",
        "outputId": "8fe479bc-9972-4264-8b6e-760223af5efb",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfaxPSTx0s09"
      },
      "source": [
        "This notebook assumes that you have copied the indexes and weights and renamed them accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bPwfMwT0fEe",
        "outputId": "aa82abca-d886-412f-fb87-b91d4012f474",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/semanticSearch-Example'\n",
            "/content/drive/MyDrive/semanticSearch-Example\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/semanticSearch-Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeMa-jOyrZUa"
      },
      "source": [
        "#Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfAPLHXTrBiw",
        "collapsed": true,
        "outputId": "e0262745-973e-4e8e-c302-3b26aae1b42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semanticSearchSbert'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 30 (delta 16), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (30/30), 9.84 KiB | 775.00 KiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JulioUriostegui19/semanticSearchSbert.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1uXkm7WrfOZ"
      },
      "source": [
        "#Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uap4gyfFrJkB",
        "outputId": "aabcd10b-68c7-416b-ca5b-f00c952ab570",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers==2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r semanticSearchSbert/requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (from -r semanticSearchSbert/requirements.txt (line 2)) (1.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r semanticSearchSbert/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r semanticSearchSbert/requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r semanticSearchSbert/requirements.txt (line 5)) (4.66.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (0.20.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (0.24.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r semanticSearchSbert/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r semanticSearchSbert/requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r semanticSearchSbert/requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r semanticSearchSbert/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers==2.2.1->-r semanticSearchSbert/requirements.txt (line 1)) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r semanticSearchSbert/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkIBipYTrieE"
      },
      "source": [
        "#Run semantic search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSdVAfh6tJi8"
      },
      "source": [
        "The --query parameter is used to provide the search query. The --model_type parameter lets you choose between the original and fine_tuned models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LfjPZelsy_Y",
        "outputId": "dc463191-e272-468e-98d5-267999c99e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.2.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))\n",
            ">>>> Results in Total Time: 0.24007296562194824\n",
            "\n",
            "Results:\n",
            "{'book_title': 'The Name of the Wind'}\n",
            "{'book_title': 'The Fire Within'}\n",
            "{'book_title': 'The Name of the Wind'}\n",
            "{'book_title': 'The Knight'}\n",
            "{'book_title': 'The Magicians'}\n"
          ]
        }
      ],
      "source": [
        "!python semanticSearchSbert/semanticSearchSbert.py --query  \"A story about a young wizard discovering his powers in a magical world\" --model_type original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xpglVc1MIWKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "dfeaa410-e29c-41a3-aa5c-511c91502c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fine_tuned.zip\n",
            "   creating: fine_tuned/\n",
            "   creating: fine_tuned/sbert_semantic_search-model/\n",
            "  inflating: fine_tuned/sbert_semantic_search-model/config_sentence_transformers.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/config.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/model.safetensors  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/tokenizer_config.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/special_tokens_map.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/vocab.txt  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/tokenizer.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/sentence_bert_config.json  \n",
            "   creating: fine_tuned/sbert_semantic_search-model/1_Pooling/\n",
            "  inflating: fine_tuned/sbert_semantic_search-model/1_Pooling/config.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/modules.json  \n",
            "  inflating: fine_tuned/sbert_semantic_search-model/README.md  \n"
          ]
        }
      ],
      "source": [
        "!unzip fine_tuned.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6m6Wcd0s3H1"
      },
      "source": [
        "The parameter --top_k let you adjust the number of results shown. Deafault is 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bi-vD8jgrYlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2ae6a0-66df-4a33-a6d5-445e00c379a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>> Results in Total Time: 0.4377720355987549\n",
            "\n",
            "Results:\n",
            "{'book_title': 'Anne Frank Remembered: The Story of the Woman Who Helped to '\n",
            "               'Hide the Frank Family'}\n",
            "{'book_title': 'The Double Life of Zoe Flynn'}\n",
            "{'book_title': 'The Vampire Diaries, Volumes 1-4'}\n",
            "{'book_title': 'The Riftwar Saga'}\n",
            "{'book_title': 'The Amish Seamstress'}\n",
            "{'book_title': 'A Gift of Three'}\n",
            "{'book_title': 'The Ghost of Opalina'}\n"
          ]
        }
      ],
      "source": [
        "!python semanticSearchSbert/semanticSearchSbert.py --query \"A story about a young wizard discovering his powers in a magical world\" --model_type fine_tuned --top_k 7"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6XVQqA-vTLFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}